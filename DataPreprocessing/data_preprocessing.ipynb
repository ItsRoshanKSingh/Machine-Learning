{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "Feature: o/p variable used in model to make prediction and Depedent Variable is output variable that model is Trying to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data/Data.csv\")\n",
    "feature_var = dataset.iloc[:, :-1].values\n",
    "dependent_var = dataset.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking Care of Missing Data\n",
    "\n",
    "Method:\n",
    "\n",
    "1. Delete if small no. of data\n",
    "2. Replace missing with (avg of all) or median or most frequent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "print(dataset)  # Still Missing value doesnt replaced with Mean\n",
    "print()\n",
    "imputer.fit(feature_var[:, 1:-1])  # The fit method computes the mean for each column\n",
    "imputer.transform(\n",
    "    feature_var[:, 1:-1]\n",
    ")  # Perform the imputation (fill in missing values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#! Encoding Categorical Data\n",
    "\n",
    "There will be some non-numerical column so it will be deficult to compute. So we will be doing encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Independent Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[(\"encoder\", OneHotEncoder(), [0])], remainder=\"passthrough\"\n",
    ")\n",
    "feature_var = ct.fit_transform(feature_var)\n",
    "print(feature_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding dependent Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "dependent_var = le.fit_transform(dependent_var)\n",
    "print(dependent_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the DataSet into Training DataSet and Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_train, feature_test, dependent_train, dependent_test = train_test_split(\n",
    "    feature_var, dependent_var, train_size=0.2, random_state=1\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"feature_train = \\n{feature_train}\\n\\n feature_test = \\n{feature_test}\\n\\n \\\n",
    "      dependent_train=\\n{dependent_train}\\n\\n dependent_test=\\n{dependent_test}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
